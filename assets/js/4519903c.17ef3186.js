"use strict";(self.webpackChunkvis_engine_docs=self.webpackChunkvis_engine_docs||[]).push([[4751],{9514:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var t=r(5250),o=r(3274);const a={id:"box-volume",title:"Draw Box Volume Geometry"},s=void 0,i={id:"playground/box-volume",title:"Draw Box Volume Geometry",description:"\u4f53\u6e32\u67d3\u5728\u6b64\u5f15\u64ce\u7684\u5b9e\u73b0\u3002",source:"@site/docs/playground/box-volume.mdx",sourceDirName:"playground",slug:"/playground/box-volume",permalink:"/vis-engine/docs/playground/box-volume",draft:!1,unlisted:!1,editUrl:"https://github.com/sakitam-gis/vis-engine/edit/master/documents/docs/docs/playground/box-volume.mdx",tags:[],version:"current",lastUpdatedBy:"sakitam-fdd",lastUpdatedAt:1711204798,formattedLastUpdatedAt:"Mar 23, 2024",frontMatter:{id:"box-volume",title:"Draw Box Volume Geometry"},sidebar:"docs",previous:{title:"Draw Box Geometry",permalink:"/vis-engine/docs/playground/box"},next:{title:"Draw Cloud",permalink:"/vis-engine/docs/playground/clouds"}},l={},c=[{value:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b",id:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b",level:3}];function m(n){const e={a:"a",code:"code",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.a)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:"\u4f53\u6e32\u67d3\u5728\u6b64\u5f15\u64ce\u7684\u5b9e\u73b0\u3002\n\u5177\u4f53\u8bf7\u53c2\u8003\u4ee5\u4e0b\u5b9e\u73b0\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://www.willusher.io/webgl/2019/01/13/volume-rendering-with-webgl",children:"https://www.willusher.io/webgl/2019/01/13/volume-rendering-with-webgl"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://juejin.cn/post/6844904056872239117",children:"https://juejin.cn/post/6844904056872239117"})}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b",children:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-jsx",metastring:"live",live:!0,children:"function render(props) {\n  const drawVolumeVertex = `#version 300 es\n    layout(location=0) in vec3 position;\n    uniform mat4 modelViewMatrix;\n    uniform mat4 projectionMatrix;\n    uniform mat4 viewMatrix;\n    uniform mat4 modelMatrix;\n    uniform vec3 cameraPosition;\n    uniform vec3 volume_scale;\n\n    out vec3 v_modelPos;\n\n    void main(void) {\n      gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n      v_modelPos = (modelMatrix * vec4(position, 1.0)).xyz;\n    }\n    `;\n\n  const drawVolumeFragment = `#version 300 es\n    precision highp int;\n    precision highp float;\n    uniform highp sampler3D volume;\n    uniform highp sampler2D colormap;\n    uniform ivec3 volume_dims;\n    uniform float dt_scale;\n    uniform vec3 cameraPosition;\n    uniform mat4 uInvTransform;\n    uniform float u_alpha;\n\n    in vec3 v_modelPos;\n    out vec4 color;\n\n    const float STEP = 1.73205081 / 256.0;\n    vec2 boxIntersection(vec3 ro, vec3 rd, vec3 boxSize) {\n        vec3 m = 1.0 / rd;\n        vec3 n = m * ro;\n        vec3 k = abs(m) * boxSize;\n        vec3 t1 = -n - k;\n        vec3 t2 = -n + k;\n        float tN = max(max(t1.x, t1.y), t1.z);\n        float tF = min(min(t2.x, t2.y), t2.z);\n        if( tN > tF || tF < 0.0) return vec2(-1.0);\n        return vec2( tN, tF );\n    }\n\n    vec4 getColor(float intensity) {\n        intensity = min(0.46, intensity) / 0.46;\n        vec2 _uv = vec2(intensity, 0);\n        vec4 color = texture(colormap, _uv);\n        float alpha = intensity;\n        if (alpha < 0.03) {\n            alpha = 0.01;\n        }\n        return vec4(color.r, color.g, color.b, alpha);\n    }\n\n    vec4 sampleAs3DTexture(vec3 texCoord) {\n        texCoord += vec3(0.5);\n        return getColor(texture(volume, texCoord).r);\n    }\n\n    vec4 shade(in vec3 P, in vec3 V) {\n      vec3 frontPos = (uInvTransform * vec4(P.xyz, 1.0)).xyz;\n      vec3 cameraPos = (uInvTransform * vec4(cameraPosition.xyz, 1.0)).xyz;\n      vec3 rayDir = normalize(frontPos - cameraPos);\n      vec3 backPos = frontPos;\n      vec2 t = boxIntersection(cameraPos, rayDir, vec3(0.5));\n      if (t.x > -1.0 && t.y > -1.0) {\n          backPos = cameraPos + rayDir * t.y;\n      }\n      float rayLength = length(backPos - frontPos);\n      int steps = int(max(1.0, floor(rayLength / STEP)));\n      float delta = rayLength / float(steps);\n      vec3 deltaDirection = rayDir * delta;\n      vec3 currentPosition = frontPos;\n      vec4 accumulatedColor = vec4(0.0);\n      float accumulatedAlpha = 0.0;\n      vec4 colorSample;\n      float alphaSample;\n      for (int i = 0; i < steps; i++) {\n          colorSample = sampleAs3DTexture(currentPosition);\n          alphaSample = colorSample.a * u_alpha;\n          alphaSample *= (1.0 - accumulatedAlpha);\n          accumulatedColor += colorSample * alphaSample;\n          accumulatedAlpha += alphaSample;\n          currentPosition += deltaDirection;\n      }\n      float transparent = accumulatedAlpha;\n      return vec4(accumulatedColor.xyz, transparent);\n    }\n\n    float linear_to_srgb(float x) {\n      if (x <= 0.0031308f) {\n          return 12.92f * x;\n      }\n      return 1.055f * pow(x, 1.f / 2.4f) - 0.055f;\n    }\n\n    void main() {\n      vec3 V = normalize(v_modelPos - cameraPosition);\n      vec3 P = v_modelPos;\n      color = shade(P, V);\n\n      color.r = linear_to_srgb(color.r);\n      color.g = linear_to_srgb(color.g);\n      color.b = linear_to_srgb(color.b);\n    }\n    `;\n\n  const refDom = useRef(null);\n  const meshRef = useRef(null);\n  const cameraRef = useRef(null);\n  const renderRef = useRef(null);\n\n  const store = leva.useCreateStore();\n\n  const fov = 60;\n  const nearZ = 0.1;\n\n  const farZ = 100;\n\n  const updateGeometry = () => {\n    if (!renderRef.current) return;\n    const geometry = new Box(renderRef.current, {\n      width: store.get('width'),\n      height: store.get('height'),\n      depth: store.get('depth'),\n\n      widthSegments: store.get('widthSegments'),\n      heightSegments: store.get('heightSegments'),\n      depthSegments: store.get('depthSegments'),\n    });\n\n    if (meshRef.current) {\n      meshRef.current.updateGeometry(geometry);\n    }\n  }\n\n  const config = {\n    fov: {\n      value: fov,\n      min: -50,\n      max: 90,\n      step: 1,\n      onChange: (fov) => {\n        if (cameraRef.current) {\n          cameraRef.current.fov = fov;\n        }\n      },\n    },\n    nearZ: {\n      value: nearZ,\n      min: -50,\n      max: 50,\n      step: 0.1,\n      onChange: (nearZ) => {\n        if (cameraRef.current) {\n          cameraRef.current.near = nearZ;\n        }\n      },\n    },\n    farZ: {\n      value: farZ,\n      min: -500,\n      max: 500,\n      step: 1,\n      onChange: (farZ) => {\n        if (cameraRef.current) {\n          cameraRef.current.far = farZ;\n        }\n      },\n    },\n    cameraPosition: {\n      value: [0, 0, 1.5],\n      onChange: (p) => {\n        if (cameraRef.current) {\n          cameraRef.current.position.set(...p);\n        }\n      },\n    },\n    width: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: () => {\n        updateGeometry();\n      },\n    },\n    height: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    depth: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    widthSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    heightSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    depthSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    wireframe: {\n      value: false,\n      onChange: (p) => {\n        if (meshRef.current) {\n          meshRef.current.wireframe = p;\n        }\n      },\n    }\n  };\n\n  leva.useControls(config, {\n    store: store,\n  });\n\n  const image = useBaseUrl('/assets/rainbow.png');\n  const volume = useBaseUrl('/assets/bonsai_256x256x256_uint8.raw');\n\n  const init = () => {\n    const canvas = refDom.current;\n\n    canvas.width = canvas.clientWidth;\n    canvas.height = canvas.clientHeight;\n    const renderer = new Renderer(canvas, {\n      alpha: false,\n      antialias: true,\n      premultipliedAlpha: true,\n    });\n\n    renderRef.current = renderer;\n\n    const camera = new PerspectiveCamera(fov, canvas.width / canvas.height, nearZ, farZ);\n    camera.position.z = 1.5;\n    cameraRef.current = camera;\n\n    function resize(target) {\n      const { width, height } = target.getBoundingClientRect();\n      renderer.setSize(width, height);\n      camera.aspect = width / height;\n    }\n\n    const scene = new Scene();\n\n    const geometry = new Box(renderer, {\n      width: 1,\n      height: 1,\n      depth: 1,\n\n      widthSegments: 1,\n      heightSegments: 1,\n      depthSegments: 1,\n    });\n\n    const texture = new Texture3D(renderer, {\n      width: 256,\n      height: 256,\n      depth: 256,\n      format: renderer.gl.RED,\n      type: renderer.gl.UNSIGNED_BYTE,\n      internalFormat: renderer.gl.R8,\n    });\n\n    const colormap = new Texture(renderer, {\n      width: 180,\n      height: 1,\n    });\n\n    colormap.fromSrc(image);\n\n    const invTransform = new ProjectionMatrix();\n\n    const program = new Program(renderer, {\n      vertexShader: drawVolumeVertex,\n      fragmentShader: drawVolumeFragment,\n      uniforms: {\n        volume: { value: texture },\n        colormap: { value: colormap },\n        volume_dims: { value: new ve.Vector3() },\n        volume_scale: { value: new ve.Vector3() },\n        u_alpha: { value: 0.6 },\n        u_invTransform: { value: invTransform },\n      },\n      cullFace: renderer.gl.FRONT,\n      // depthTest: true,\n      blendFunc: {\n        src: renderer.gl.ONE,\n        dst: renderer.gl.ONE_MINUS_SRC_ALPHA,\n        srcAlpha: renderer.gl.ONE,\n        dstAlpha: renderer.gl.ONE_MINUS_SRC_ALPHA,\n      },\n      blendEquation: {\n        modeRGB: renderer.gl.FUNC_ADD,\n        modeAlpha: renderer.gl.FUNC_ADD,\n      },\n    });\n\n    function loadVolume(url) {\n      const fileRegex = /.*\\/(\\w+)_(\\d+)x(\\d+)x(\\d+)_(\\w+)\\.*/;\n      const m = url.match(fileRegex);\n\t\t  const volDims = [parseInt(m[2]), parseInt(m[3]), parseInt(m[4])];\n      const req = new XMLHttpRequest();\n\n      req.open(\"GET\", url, true);\n      req.responseType = \"arraybuffer\";\n\n      req.onerror = function(evt) {\n        console.error(evt);\n      };\n      req.onload = function() {\n        const dataBuffer = req.response;\n        if (dataBuffer) {\n          const d = new Uint8Array(dataBuffer);\n          const longestAxis = Math.max(volDims[0], Math.max(volDims[1], volDims[2]));\n          const volScale = [\n            volDims[0] / longestAxis,\n            volDims[1] / longestAxis,\n            volDims[2] / longestAxis,\n          ];\n          texture.setData(d, volDims[0], volDims[1], volDims[2]);\n          program.setUniform('volume_dims', new Vector3().fromArray(volDims));\n          program.setUniform('volume_scale', new Vector3().fromArray(volScale));\n        } else {\n          console.log(\"\u65e0\u6570\u636e\");\n        }\n      };\n      req.send();\n    }\n\n    const box = new Mesh(renderer, {\n      geometry,\n      program,\n      mode: renderer.gl.TRIANGLE_STRIP,\n      // wireframe: true,\n    });\n    box.setParent(scene);\n    box.position.set(0, 0, 0);\n\n    meshRef.current = box;\n\n    loadVolume(volume);\n\n    const raf = new Raf((t) => {\n      box.rotation.y -= 0.01;\n      box.rotation.z -= 0.01;\n      invTransform.copy(box.localMatrix).invert()\n      program.setUniform('uInvTransform', invTransform);\n      renderer.render({ scene, camera });\n    });\n\n    return {\n      canvas,\n      resize,\n    }\n  }\n\n  useEffect(() => {\n    const { canvas, resize } = init();\n\n    observe(canvas, resize);\n\n    return () => {\n      unobserve(canvas, resize);\n    };\n  }, []);\n\n  return (\n    <div className=\"live-wrap\">\n      <div className=\"leva-wrap\">\n        <Leva\n          collapsed\n          fill\n        ></Leva>\n        <LevaPanel collapsed store={store} fill></LevaPanel>\n      </div>\n      <canvas className=\"scene-canvas\" ref={refDom}></canvas>\n    </div>\n  );\n}\n"})})]})}function u(n={}){const{wrapper:e}={...(0,o.a)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(m,{...n})}):m(n)}},3274:(n,e,r)=>{r.d(e,{Z:()=>i,a:()=>s});var t=r(79);const o={},a=t.createContext(o);function s(n){const e=t.useContext(a);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);