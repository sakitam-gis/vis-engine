"use strict";(self.webpackChunkvis_engine_docs=self.webpackChunkvis_engine_docs||[]).push([[4751],{8570:(n,e,r)=>{r.d(e,{Zo:()=>m,kt:()=>d});var t=r(79);function o(n,e,r){return e in n?Object.defineProperty(n,e,{value:r,enumerable:!0,configurable:!0,writable:!0}):n[e]=r,n}function a(n,e){var r=Object.keys(n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(n);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),r.push.apply(r,t)}return r}function i(n){for(var e=1;e<arguments.length;e++){var r=null!=arguments[e]?arguments[e]:{};e%2?a(Object(r),!0).forEach((function(e){o(n,e,r[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(r,e))}))}return n}function l(n,e){if(null==n)return{};var r,t,o=function(n,e){if(null==n)return{};var r,t,o={},a=Object.keys(n);for(t=0;t<a.length;t++)r=a[t],e.indexOf(r)>=0||(o[r]=n[r]);return o}(n,e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(n);for(t=0;t<a.length;t++)r=a[t],e.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(n,r)&&(o[r]=n[r])}return o}var s=t.createContext({}),c=function(n){var e=t.useContext(s),r=e;return n&&(r="function"==typeof n?n(e):i(i({},e),n)),r},m=function(n){var e=c(n.components);return t.createElement(s.Provider,{value:e},n.children)},u="mdxType",p={inlineCode:"code",wrapper:function(n){var e=n.children;return t.createElement(t.Fragment,{},e)}},v=t.forwardRef((function(n,e){var r=n.components,o=n.mdxType,a=n.originalType,s=n.parentName,m=l(n,["components","mdxType","originalType","parentName"]),u=c(r),v=o,d=u["".concat(s,".").concat(v)]||u[v]||p[v]||a;return r?t.createElement(d,i(i({ref:e},m),{},{components:r})):t.createElement(d,i({ref:e},m))}));function d(n,e){var r=arguments,o=e&&e.mdxType;if("string"==typeof n||o){var a=r.length,i=new Array(a);i[0]=v;var l={};for(var s in e)hasOwnProperty.call(e,s)&&(l[s]=e[s]);l.originalType=n,l[u]="string"==typeof n?n:o,i[1]=l;for(var c=2;c<a;c++)i[c]=r[c];return t.createElement.apply(null,i)}return t.createElement.apply(null,r)}v.displayName="MDXCreateElement"},6264:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>m,contentTitle:()=>s,default:()=>v,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var t=r(7583),o=r(2475),a=(r(79),r(8570)),i=["components"],l={id:"box-volume",title:"Draw Box Volume Geometry"},s=void 0,c={unversionedId:"playground/box-volume",id:"playground/box-volume",title:"Draw Box Volume Geometry",description:"\u4f53\u6e32\u67d3\u5728\u6b64\u5f15\u64ce\u7684\u5b9e\u73b0\u3002",source:"@site/docs/playground/box-volume.mdx",sourceDirName:"playground",slug:"/playground/box-volume",permalink:"/vis-engine/docs/playground/box-volume",draft:!1,editUrl:"https://github.com/sakitam-gis/vis-engine/edit/master/documents/docs/docs/playground/box-volume.mdx",tags:[],version:"current",lastUpdatedBy:"sakitam-fdd",lastUpdatedAt:1678692004,formattedLastUpdatedAt:"Mar 13, 2023",frontMatter:{id:"box-volume",title:"Draw Box Volume Geometry"},sidebar:"docs",previous:{title:"Draw Box Geometry",permalink:"/vis-engine/docs/playground/box"},next:{title:"Draw Cloud",permalink:"/vis-engine/docs/playground/clouds"}},m={},u=[{value:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b",id:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b",level:3}],p={toc:u};function v(n){var e=n.components,r=(0,o.Z)(n,i);return(0,a.kt)("wrapper",(0,t.Z)({},p,r,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"\u4f53\u6e32\u67d3\u5728\u6b64\u5f15\u64ce\u7684\u5b9e\u73b0\u3002\n\u5177\u4f53\u8bf7\u53c2\u8003\u4ee5\u4e0b\u5b9e\u73b0\uff1a"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://www.willusher.io/webgl/2019/01/13/volume-rendering-with-webgl"},"https://www.willusher.io/webgl/2019/01/13/volume-rendering-with-webgl")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://juejin.cn/post/6844904056872239117"},"https://juejin.cn/post/6844904056872239117"))),(0,a.kt)("h3",{id:"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b"},"\u4e00\u4e2a\u7b80\u5355\u7684\u793a\u4f8b"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-jsx",metastring:"live",live:!0},"function render(props) {\n  const drawVolumeVertex = `#version 300 es\n    layout(location=0) in vec3 position;\n    uniform mat4 modelViewMatrix;\n    uniform mat4 projectionMatrix;\n    uniform mat4 viewMatrix;\n    uniform mat4 modelMatrix;\n    uniform vec3 cameraPosition;\n    uniform vec3 volume_scale;\n\n    out vec3 v_modelPos;\n\n    void main(void) {\n      gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n      v_modelPos = (modelMatrix * vec4(position, 1.0)).xyz;\n    }\n    `;\n\n  const drawVolumeFragment = `#version 300 es\n    precision highp int;\n    precision highp float;\n    uniform highp sampler3D volume;\n    uniform highp sampler2D colormap;\n    uniform ivec3 volume_dims;\n    uniform float dt_scale;\n    uniform vec3 cameraPosition;\n    uniform mat4 uInvTransform;\n    uniform float u_alpha;\n\n    in vec3 v_modelPos;\n    out vec4 color;\n\n    const float STEP = 1.73205081 / 256.0;\n    vec2 boxIntersection(vec3 ro, vec3 rd, vec3 boxSize) {\n        vec3 m = 1.0 / rd;\n        vec3 n = m * ro;\n        vec3 k = abs(m) * boxSize;\n        vec3 t1 = -n - k;\n        vec3 t2 = -n + k;\n        float tN = max(max(t1.x, t1.y), t1.z);\n        float tF = min(min(t2.x, t2.y), t2.z);\n        if( tN > tF || tF < 0.0) return vec2(-1.0);\n        return vec2( tN, tF );\n    }\n\n    vec4 getColor(float intensity) {\n        intensity = min(0.46, intensity) / 0.46;\n        vec2 _uv = vec2(intensity, 0);\n        vec4 color = texture(colormap, _uv);\n        float alpha = intensity;\n        if (alpha < 0.03) {\n            alpha = 0.01;\n        }\n        return vec4(color.r, color.g, color.b, alpha);\n    }\n\n    vec4 sampleAs3DTexture(vec3 texCoord) {\n        texCoord += vec3(0.5);\n        return getColor(texture(volume, texCoord).r);\n    }\n\n    vec4 shade(in vec3 P, in vec3 V) {\n      vec3 frontPos = (uInvTransform * vec4(P.xyz, 1.0)).xyz;\n      vec3 cameraPos = (uInvTransform * vec4(cameraPosition.xyz, 1.0)).xyz;\n      vec3 rayDir = normalize(frontPos - cameraPos);\n      vec3 backPos = frontPos;\n      vec2 t = boxIntersection(cameraPos, rayDir, vec3(0.5));\n      if (t.x > -1.0 && t.y > -1.0) {\n          backPos = cameraPos + rayDir * t.y;\n      }\n      float rayLength = length(backPos - frontPos);\n      int steps = int(max(1.0, floor(rayLength / STEP)));\n      float delta = rayLength / float(steps);\n      vec3 deltaDirection = rayDir * delta;\n      vec3 currentPosition = frontPos;\n      vec4 accumulatedColor = vec4(0.0);\n      float accumulatedAlpha = 0.0;\n      vec4 colorSample;\n      float alphaSample;\n      for (int i = 0; i < steps; i++) {\n          colorSample = sampleAs3DTexture(currentPosition);\n          alphaSample = colorSample.a * u_alpha;\n          alphaSample *= (1.0 - accumulatedAlpha);\n          accumulatedColor += colorSample * alphaSample;\n          accumulatedAlpha += alphaSample;\n          currentPosition += deltaDirection;\n      }\n      float transparent = accumulatedAlpha;\n      return vec4(accumulatedColor.xyz, transparent);\n    }\n\n    float linear_to_srgb(float x) {\n      if (x <= 0.0031308f) {\n          return 12.92f * x;\n      }\n      return 1.055f * pow(x, 1.f / 2.4f) - 0.055f;\n    }\n\n    void main() {\n      vec3 V = normalize(v_modelPos - cameraPosition);\n      vec3 P = v_modelPos;\n      color = shade(P, V);\n\n      color.r = linear_to_srgb(color.r);\n      color.g = linear_to_srgb(color.g);\n      color.b = linear_to_srgb(color.b);\n    }\n    `;\n\n  const refDom = useRef(null);\n  const meshRef = useRef(null);\n  const cameraRef = useRef(null);\n  const renderRef = useRef(null);\n\n  const store = leva.useCreateStore();\n\n  const fov = 60;\n  const nearZ = 0.1;\n\n  const farZ = 100;\n\n  const updateGeometry = () => {\n    if (!renderRef.current) return;\n    const geometry = new Box(renderRef.current, {\n      width: store.get('width'),\n      height: store.get('height'),\n      depth: store.get('depth'),\n\n      widthSegments: store.get('widthSegments'),\n      heightSegments: store.get('heightSegments'),\n      depthSegments: store.get('depthSegments'),\n    });\n\n    if (meshRef.current) {\n      meshRef.current.updateGeometry(geometry);\n    }\n  }\n\n  const config = {\n    fov: {\n      value: fov,\n      min: -50,\n      max: 90,\n      step: 1,\n      onChange: (fov) => {\n        if (cameraRef.current) {\n          cameraRef.current.fov = fov;\n        }\n      },\n    },\n    nearZ: {\n      value: nearZ,\n      min: -50,\n      max: 50,\n      step: 0.1,\n      onChange: (nearZ) => {\n        if (cameraRef.current) {\n          cameraRef.current.near = nearZ;\n        }\n      },\n    },\n    farZ: {\n      value: farZ,\n      min: -500,\n      max: 500,\n      step: 1,\n      onChange: (farZ) => {\n        if (cameraRef.current) {\n          cameraRef.current.far = farZ;\n        }\n      },\n    },\n    cameraPosition: {\n      value: [0, 0, 1.5],\n      onChange: (p) => {\n        if (cameraRef.current) {\n          cameraRef.current.position.set(...p);\n        }\n      },\n    },\n    width: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: () => {\n        updateGeometry();\n      },\n    },\n    height: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    depth: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    widthSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    heightSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    depthSegments: {\n      value: 1,\n      min: 1,\n      max: 100,\n      step: 1,\n      onChange: (p) => {\n        updateGeometry();\n      },\n    },\n    wireframe: {\n      value: false,\n      onChange: (p) => {\n        if (meshRef.current) {\n          meshRef.current.wireframe = p;\n        }\n      },\n    }\n  };\n\n  leva.useControls(config, {\n    store: store,\n  });\n\n  const image = useBaseUrl('/assets/rainbow.png');\n  const volume = useBaseUrl('/assets/bonsai_256x256x256_uint8.raw');\n\n  const init = () => {\n    const canvas = refDom.current;\n\n    canvas.width = canvas.clientWidth;\n    canvas.height = canvas.clientHeight;\n    const renderer = new Renderer(canvas, {\n      alpha: false,\n      antialias: true,\n      premultipliedAlpha: true,\n    });\n\n    renderRef.current = renderer;\n\n    const camera = new PerspectiveCamera(fov, canvas.width / canvas.height, nearZ, farZ);\n    camera.position.z = 1.5;\n    cameraRef.current = camera;\n\n    function resize(target) {\n      const { width, height } = target.getBoundingClientRect();\n      renderer.setSize(width, height);\n      camera.aspect = width / height;\n    }\n\n    const scene = new Scene();\n\n    const geometry = new Box(renderer, {\n      width: 1,\n      height: 1,\n      depth: 1,\n\n      widthSegments: 1,\n      heightSegments: 1,\n      depthSegments: 1,\n    });\n\n    const texture = new Texture3D(renderer, {\n      width: 256,\n      height: 256,\n      depth: 256,\n      format: renderer.gl.RED,\n      type: renderer.gl.UNSIGNED_BYTE,\n      internalFormat: renderer.gl.R8,\n    });\n\n    const colormap = new Texture(renderer, {\n      width: 180,\n      height: 1,\n    });\n\n    colormap.fromSrc(image);\n\n    const invTransform = new ProjectionMatrix();\n\n    const program = new Program(renderer, {\n      vertexShader: drawVolumeVertex,\n      fragmentShader: drawVolumeFragment,\n      uniforms: {\n        volume: { value: texture },\n        colormap: { value: colormap },\n        volume_dims: { value: new ve.Vector3() },\n        volume_scale: { value: new ve.Vector3() },\n        u_alpha: { value: 0.6 },\n        u_invTransform: { value: invTransform },\n      },\n      cullFace: renderer.gl.FRONT,\n      // depthTest: true,\n      blendFunc: {\n        src: renderer.gl.ONE,\n        dst: renderer.gl.ONE_MINUS_SRC_ALPHA,\n        srcAlpha: renderer.gl.ONE,\n        dstAlpha: renderer.gl.ONE_MINUS_SRC_ALPHA,\n      },\n      blendEquation: {\n        modeRGB: renderer.gl.FUNC_ADD,\n        modeAlpha: renderer.gl.FUNC_ADD,\n      },\n    });\n\n    function loadVolume(url) {\n      const fileRegex = /.*\\/(\\w+)_(\\d+)x(\\d+)x(\\d+)_(\\w+)\\.*/;\n      const m = url.match(fileRegex);\n          const volDims = [parseInt(m[2]), parseInt(m[3]), parseInt(m[4])];\n      const req = new XMLHttpRequest();\n\n      req.open(\"GET\", url, true);\n      req.responseType = \"arraybuffer\";\n\n      req.onerror = function(evt) {\n        console.error(evt);\n      };\n      req.onload = function() {\n        const dataBuffer = req.response;\n        if (dataBuffer) {\n          const d = new Uint8Array(dataBuffer);\n          const longestAxis = Math.max(volDims[0], Math.max(volDims[1], volDims[2]));\n          const volScale = [\n            volDims[0] / longestAxis,\n            volDims[1] / longestAxis,\n            volDims[2] / longestAxis,\n          ];\n          texture.setData(d, volDims[0], volDims[1], volDims[2]);\n          program.setUniform('volume_dims', new Vector3().fromArray(volDims));\n          program.setUniform('volume_scale', new Vector3().fromArray(volScale));\n        } else {\n          console.log(\"\u65e0\u6570\u636e\");\n        }\n      };\n      req.send();\n    }\n\n    const box = new Mesh(renderer, {\n      geometry,\n      program,\n      mode: renderer.gl.TRIANGLE_STRIP,\n      // wireframe: true,\n    });\n    box.setParent(scene);\n    box.position.set(0, 0, 0);\n\n    meshRef.current = box;\n\n    loadVolume(volume);\n\n    const raf = new Raf((t) => {\n      box.rotation.y -= 0.01;\n      box.rotation.z -= 0.01;\n      invTransform.copy(box.localMatrix).invert()\n      program.setUniform('uInvTransform', invTransform);\n      renderer.render({ scene, camera });\n    });\n\n    return {\n      canvas,\n      resize,\n    }\n  }\n\n  useEffect(() => {\n    const { canvas, resize } = init();\n\n    observe(canvas, resize);\n\n    return () => {\n      unobserve(canvas, resize);\n    };\n  }, []);\n\n  return (\n    <div className=\"live-wrap\">\n      <div className=\"leva-wrap\">\n        <Leva\n          collapsed\n          fill\n        ></Leva>\n        <LevaPanel collapsed store={store} fill></LevaPanel>\n      </div>\n      <canvas className=\"scene-canvas\" ref={refDom}></canvas>\n    </div>\n  );\n}\n")))}v.isMDXComponent=!0}}]);